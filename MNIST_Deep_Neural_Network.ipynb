{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fqWxiVaY0f_B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adversarial_attack(input_data, model, labels, epsilon) :\n",
        "  alpha = 0.2\n",
        "  input_data.requires_grad = True\n",
        "\n",
        "  outputs, _ = model(input_data)\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  loss = loss_func(outputs, labels)\n",
        "\n",
        "  model.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  perturbation = alpha * input_data.grad.data.sign()\n",
        "  perturbed_data = input_data + perturbation\n",
        "  perturbed_data = torch.clamp(perturbed_data, input_data-epsilon, input_data+epsilon)\n",
        "\n",
        "  return perturbed_data\n"
      ],
      "metadata": {
        "id": "8wlfM6ADixFZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(root = 'data', train = True, transform = transforms.ToTensor(), download = True)\n",
        "\n",
        "test_data = datasets.MNIST(root = 'data', train = False, transform = transforms.ToTensor())\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "994O5EN51zbf",
        "outputId": "7ccdd1c7-3e58-473f-9a24-509d212473f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = {\n",
        "    'train' : DataLoader(train_data, batch_size = 100, shuffle = True),\n",
        "\n",
        "    'test' :  DataLoader(test_data, batch_size = 100, shuffle = True)\n",
        "}"
      ],
      "metadata": {
        "id": "zH9bAlqk5ShI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super (LinearModel, self).__init__()\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.out1 = nn.Linear(28 * 28, 128)\n",
        "    self.activation1 = nn.ReLU()\n",
        "    self.out2 = nn.Linear(128, 10)\n",
        "    self.activation2 = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.flatten(x)\n",
        "      x = self.out1(x)\n",
        "      x = self.activation1(x)\n",
        "      x = self.out2(x)\n",
        "      output = self.activation2(x)\n",
        "      return output, x\n",
        "\n",
        "linear_model = LinearModel();\n",
        "print(linear_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym8yO-Gg64IF",
        "outputId": "19dbfb02-e589-4fc2-92e8-90a301d53ed0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearModel(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (out1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (activation1): ReLU()\n",
            "  (out2): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (activation2): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "CKnwIrAq_pt4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(linear_model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "PE55CJON_7FX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "def train(num_epochs, linear, loaders):\n",
        "\n",
        "  linear.train()\n",
        "\n",
        "  total_step = len(loaders['train'])\n",
        "\n",
        "  for epoch in range(num_epochs) :\n",
        "    for i, (images, labels) in enumerate(loaders['train']):\n",
        "\n",
        "      b_x = images\n",
        "      b_y = labels\n",
        "\n",
        "      output = linear(b_x)[0]\n",
        "      loss = loss_function(output, b_y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if (i+1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "train(num_epochs, linear_model, loaders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9t2PNsnATAn",
        "outputId": "a8755d34-461c-4594-e616-bf3a5d8cce7f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 1.5695\n",
            "Epoch [1/5], Step [200/600], Loss: 1.5455\n",
            "Epoch [1/5], Step [300/600], Loss: 1.5249\n",
            "Epoch [1/5], Step [400/600], Loss: 1.5550\n",
            "Epoch [1/5], Step [500/600], Loss: 1.5047\n",
            "Epoch [1/5], Step [600/600], Loss: 1.5305\n",
            "Epoch [2/5], Step [100/600], Loss: 1.4818\n",
            "Epoch [2/5], Step [200/600], Loss: 1.4882\n",
            "Epoch [2/5], Step [300/600], Loss: 1.5222\n",
            "Epoch [2/5], Step [400/600], Loss: 1.4826\n",
            "Epoch [2/5], Step [500/600], Loss: 1.5062\n",
            "Epoch [2/5], Step [600/600], Loss: 1.4985\n",
            "Epoch [3/5], Step [100/600], Loss: 1.4921\n",
            "Epoch [3/5], Step [200/600], Loss: 1.4855\n",
            "Epoch [3/5], Step [300/600], Loss: 1.4978\n",
            "Epoch [3/5], Step [400/600], Loss: 1.5034\n",
            "Epoch [3/5], Step [500/600], Loss: 1.4883\n",
            "Epoch [3/5], Step [600/600], Loss: 1.5115\n",
            "Epoch [4/5], Step [100/600], Loss: 1.4886\n",
            "Epoch [4/5], Step [200/600], Loss: 1.5140\n",
            "Epoch [4/5], Step [300/600], Loss: 1.4997\n",
            "Epoch [4/5], Step [400/600], Loss: 1.5070\n",
            "Epoch [4/5], Step [500/600], Loss: 1.5052\n",
            "Epoch [4/5], Step [600/600], Loss: 1.5105\n",
            "Epoch [5/5], Step [100/600], Loss: 1.4739\n",
            "Epoch [5/5], Step [200/600], Loss: 1.4991\n",
            "Epoch [5/5], Step [300/600], Loss: 1.4850\n",
            "Epoch [5/5], Step [400/600], Loss: 1.4712\n",
            "Epoch [5/5], Step [500/600], Loss: 1.5139\n",
            "Epoch [5/5], Step [600/600], Loss: 1.4780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  linear_model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for images, labels in loaders['test']:\n",
        "        perturbed_images = adversarial_attack(images, linear_model, labels, 0.1)\n",
        "        test_output = linear_model(perturbed_images)[0]\n",
        "        _, pred_y = torch.max(test_output, 1)\n",
        "\n",
        "  accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
        "\n",
        "  print('Test Accuracy: %.2f' % accuracy)\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48cHj2TWFxD1",
        "outputId": "840773ed-7fff-4749-865e-4246b82cec53"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in loaders['test']:\n",
        "    perturbed_images = adversarial_attack(images, linear_model, labels, 0.05)\n",
        "    break\n",
        "\n",
        "image_array = perturbed_images[0].detach().squeeze().numpy()\n",
        "\n",
        "# Display the image using Matplotlib\n",
        "plt.imshow(image_array, cmap='gray')\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "yzQHGvU-lqkq",
        "outputId": "2a969fc2-2633-4860-c908-c15e7812ee34"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}